---
layout: single
title: "[Python] í…ìŠ¤íŠ¸ ìœ ì‚¬ë„"
categories: Data_Analysis
tags: [NLP, python]
toc: True
author_profile: False
sidebar:
    nav: "docs"
---

### ğŸ” í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (Text Similarity)

- í…ìŠ¤íŠ¸ê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ íŒë‹¨í•˜ëŠ” ê²ƒ<br>
<br>
- ìœ ì‚¬ë„ ì¸¡ì •ë°©ë²•<br>
1) ë‹¨ì–´ ê°œìˆ˜ ë¹ˆë„ ì²´í¬<br>
2) í˜•íƒœì†Œë¡œ ë‚˜ëˆ  í˜•íƒœì†Œ ë¹„êµ<br>
3) ìì†Œ ë‹¨ìœ„ë¡œ ë‚˜ëˆ  ë‹¨ì–´ë¥¼ ë¹„êµí•˜ëŠ” ë°©ë²•<br>

#### Deep Learning  ê¸°ë°˜ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ì¸¡ì • <br>
1) í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°í™”<br>
2) ë²¡í„°í™”ëœ ê° ë¬¸ì¥ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰ ë¨<br>

#### ìì£¼ ì“°ì´ëŠ” ìœ ì‚¬ë„ 4ê°€ì§€ ì¸¡ì •ë°©ë²•<br>
1) `ìì¹´ë“œ` ìœ ì‚¬ë„<br>
2) `ìœ í´ë¦¬ë””ì–¸` ìœ ì‚¬ë„<br>
3) `ë§¨í•´íŠ¼` ìœ ì‚¬ë„<br>
4) `ì½”ì‚¬ì¸` ìœ ì‚¬ë„<br>

---

#### TF-IDF (Team Frequency - Inverse Document Frequency)


```python
from sklearn.feature_extraction.text import TfidfVectorizer

# ë‚´ê°€ ë§Œë“  ë¬¸ì¥

sentence =("íœ´ì¼ì¸ ì˜¤ëŠ˜ë„ ë¹„ê°€ ì™€ì„œ ë§ì€ ì‚¬ëŒë“¤ì´ ì™¸ì¶œì„ ì•ˆ í•˜ê³  ì§‘ì—ì„œ ì‰´ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.",
          "ì‚¬ëŒë“¤ì€ ì•„ë¬´ë„ ì˜¤ëŠ˜ ë¹„ê°€ ì˜¬ì§€ ì˜ˆìƒí•˜ì§€ ëª»í–ˆë‹¤. ê¸°ìƒì²­ì€ ê°•í•œ ë°”ëŒê³¼ ë§ì€ ì–‘ì˜ ë¹„ê°€ ì˜¨ë‹¤ê³  ì˜ˆë³´í–ˆë‹¤.")

tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(sentence) #ë²¡í„°í™”í•  ë¬¸ì¥ ë„£ì–´ì£¼ê¸°

idf = tfidf_vectorizer.idf_
print(dict(zip(tfidf_vectorizer.get_feature_names(), idf))) # ê° ìˆ˜ì¹˜ì— ëŒ€í•œ ì‹œê°í™”
```

    {'ê°•í•œ': 1.4054651081081644, 'ê²ƒìœ¼ë¡œ': 1.4054651081081644, 'ê¸°ìƒì²­ì€': 1.4054651081081644, 'ë§ì€': 1.0, 'ëª»í–ˆë‹¤': 1.4054651081081644, 'ë°”ëŒê³¼': 1.4054651081081644, 'ë³´ì…ë‹ˆë‹¤': 1.4054651081081644, 'ë¹„ê°€': 1.0, 'ì‚¬ëŒë“¤ì€': 1.4054651081081644, 'ì‚¬ëŒë“¤ì´': 1.4054651081081644, 'ì•„ë¬´ë„': 1.4054651081081644, 'ì–‘ì˜': 1.4054651081081644, 'ì˜ˆë³´í–ˆë‹¤': 1.4054651081081644, 'ì˜ˆìƒí•˜ì§€': 1.4054651081081644, 'ì˜¤ëŠ˜': 1.4054651081081644, 'ì˜¤ëŠ˜ë„': 1.4054651081081644, 'ì˜¨ë‹¤ê³ ': 1.4054651081081644, 'ì˜¬ì§€': 1.4054651081081644, 'ì™€ì„œ': 1.4054651081081644, 'ì™¸ì¶œì„': 1.4054651081081644, 'ì§‘ì—ì„œ': 1.4054651081081644, 'í•˜ê³ ': 1.4054651081081644, 'íœ´ì¼ì¸': 1.4054651081081644}
    

    C:\Anaconda\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    

### TF-IDF ë²¡í„°í™”í•œ ê°’ì€  ìì¹´ë“œ ìœ ì‚¬ë„ë¥¼ ì œì™¸í•œ ìœ ì‚¬ë„ ì¸¡ì •ì— ì‚¬ìš©ë¨

### ìì¹´ë“œ ìœ ì‚¬ë„ëŠ” ë²¡í„°í™” ì—†ì´ ë°”ë¡œ ìœ ì‚¬ë„ ì¸¡ì •ì´ ê°€ëŠ¥!

#### 1. ìì¹´ë“œ ìœ ì‚¬ë„: 2ê°œ ë¬¸ì¥ì„ ê°ê° ë‹¨ì–´ì˜ ì§‘í•©ìœ¼ë¡œ ë§Œë“  ë’¤ 2ê°œ ì§‘í•©ì„ í†µí•´ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ì‹
- êµì§‘í•©ì˜ ë‹¨ì–´ë¥¼ í•©ì§‘í•© (ì „ì²´ ë‹¨ì–´ì˜ ìˆ˜)ë¡œ ë‚˜ëˆ„ë©´ ë¨
- ê³µí†µ ì›ì†Œì˜ ê°œìˆ˜ì— ë”°ë¼ 0 ~ 1 ê°’ì´ ë‚˜ì˜¤ê³ , 1ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ë‹¤


A = {íœ´ì¼,ì¸,ì˜¤ëŠ˜,ë„,ë¹„,ê°€,ì™€ì„œ,ë§,ì€,ì‚¬ëŒ,ë“¤,ì´,ì™¸ì¶œ,ì„,ì•ˆ,í•˜ê³ ,ì§‘,ì—ì„œ,ì‰´,ê²ƒ,ìœ¼ë¡œ,ë³´ì…ë‹ˆë‹¤}<br>
B = {ì‚¬ëŒ,ë“¤,ì€,ì•„ë¬´ë„,ì˜¤ëŠ˜,ë¹„,ê°€,ì˜¬,ì§€,ì˜ˆìƒ,í•˜,ì§€,ëª»í–ˆë‹¤,ê¸°ìƒì²­,ì€,ê°•í•œ,ë°”ëŒ,ê³¼,ë§,ì€,ì–‘,ì˜,ë¹„,ê°€,ì˜¨ë‹¤ê³ ,ì˜ˆë³´,í–ˆë‹¤}

ìì¹´ë“œ ìœ ì‚¬ë„ = 8 / 35 = 0.228

#### 2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„:  ì‚¬ì´í‚·ëŸ°ì—ì„œ ìœ ì‚¬ë„ ì¸¡ì •í•¨ìˆ˜ `cosine_similarity` import í•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤.

- ë‚´ì ê³µê°„ì˜ ë‘ ë²¡í„°ê°„ ê°ë„ì˜ ì½”ì‚¬ì¸ê°’ì„ ì´ìš©í•˜ì—¬ ì¸¡ì •ëœ ë²¡í„°ê°„ì˜ ìœ ì‚¬í•œ ì •ë„ë¥¼ ì˜ë¯¸í•œë‹¤. <br>
- ê°ë„ê°€ 0Â°ì¼ ë•Œì˜ ì½”ì‚¬ì¸ê°’ì€ 1ì´ë©°, ë‹¤ë¥¸ ëª¨ë“  ê°ë„ì˜ ì½”ì‚¬ì¸ê°’ì€ 1ë³´ë‹¤ ì‘ë‹¤.<br>
- ê³µì‹: 
![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/2a8c50526e2cc7aa837477be87eff1ea703f9dec)


```python
from sklearn.metrics.pairwise import cosine_similarity

cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]) # ì²«ë²ˆì§¸ ë¬¸ì¥ê³¼ ë‘ë²ˆì§¸ ë¬¸ì¥ ë¹„êµ
```




    array([[0.12590967]])




```python
round(result[0][0], 2)
```




    0.13




```python
result = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])
print(f'ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’ì€ {round(result[0][0], 2)} ì´ë©°,')
print(f'ìœ ì‚¬ ì •ë„ëŠ” {round(result[0][0],2)*100} ì  ì…ë‹ˆë‹¤.')
```

    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’ì€ 0.13 ì´ë©°,
    ìœ ì‚¬ ì •ë„ëŠ” 13.0 ì  ì…ë‹ˆë‹¤.
    

#### 3. ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„:  ì‚¬ì´í‚·ëŸ°ì—ì„œ `euclidean_distances` import í•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤.
 - `L2 ê±°ë¦¬`ë¼ê³ ë„ í•¨<br>
 <br>
 - `ìœ„í‚¤í”¼ë””ì•„ ì„¤ëª… ì°¸ì¡°`
 - ì§êµ ì¢Œí‘œê³„ë¡œ ë‚˜íƒ€ë‚¸ ì  p = (p1, p2,..., pn)ì™€ q = (q1, q2,..., qn)ê°€ ìˆì„ ë•Œ, 
 - ë‘ ìœ í´ë¦¬ë“œ ë…¸ë¦„ì„ ì´ìš©í•˜ì—¬ ë‘ ì  p, qì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

 ![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/2e0c9ce1b3455cb9e92c6bad6684dbda02f69c82)


<br>
<br>
- ë‹¨ìˆœí•œ 2ê°œ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ëœ»í•˜ê¸° ë•Œë¬¸ì— ì–‘ìˆ˜ë¡œ ì œí•œì´ ì—†ìŒ<br>
- ì•ì˜ ìœ ì‚¬ë„ì™€ ë¹„êµí•˜ê¸° ìœ„í•´ ì¼ë°˜í™” (L1_Normalize) ì§„í–‰


```python
from sklearn.metrics.pairwise import euclidean_distances

euclidean_distances(tfidf_matrix[0:1], tfidf_matrix[1:2]) # ì²«ë²ˆì§¸ ë¬¸ì¥ê³¼ ë‘ë²ˆì§¸ ë¬¸ì¥ ë¹„êµ
```




    array([[1.32218783]])




```python
result2 = euclidean_distances(tfidf_matrix[0:1], tfidf_matrix[1:2])
print(f'ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„ ê°’ì€ {round(result2[0][0], 2)} ì´ë©°, ìœ ì‚¬ë„ëŠ” {round(result2[0][0],2)*100} ì  ì…ë‹ˆë‹¤.')
```

    ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„ ê°’ì€ 1.32 ì´ë©°, ìœ ì‚¬ë„ëŠ” 132.0 ì  ì…ë‹ˆë‹¤.
    


```python
import numpy as np

def l1_normalize(v):
    norm = np.sum(v)
    return v / norm


tfidf_norm_l1 = l1_normalize(tfidf_matrix)
e_d = euclidean_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2])
```

####  4. ë§¨í•´íŠ¼ ìœ ì‚¬ë„:  ì‚¬ì´í‚·ëŸ°ì—ì„œ `manhattan_distances` import í•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤.
 - `L1 ê±°ë¦¬`ë¼ê³ ë„ í•¨<br>
 <br>
 [ìœ„í‚¤í”¼ë””ì•„ ì„¤ëª… ì°¸ì¡°](https://ko.wikipedia.org/wiki/%EB%A7%A8%ED%95%B4%ED%8A%BC_%EA%B1%B0%EB%A6%AC)

![image](https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Manhattan_distance.svg/200px-Manhattan_distance.svg)
![image](https://commons.wikimedia.org/wiki/File:Manhattan_distance.svg)


<br>
<br>
- ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë‹¨ìˆœí•œ 2ê°œ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ëœ»í•˜ê¸° ë•Œë¬¸ì— ì–‘ìˆ˜ë¡œ ì œí•œì´ ì—†ìŒ<br>
- ì•ì˜ ìœ ì‚¬ë„ì™€ ë¹„êµí•˜ê¸° ìœ„í•´ ì¼ë°˜í™” (L1_Normalize) ì§„í–‰


```python
from sklearn.metrics.pairwise import manhattan_distances

m_d = manhattan_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2])
```

---

### ë¬¸ì¥ ìœ ì‚¬ë„ ì¸¡ì • ê²°ê³¼


```python
print('ìì¹´ë“œ ìœ ì‚¬ë„ ê°’:', 0.228)
print(f'ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’: {round(result[0][0], 2)}')
print(f'ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„ ê°’: {np.round(e_d, 2)[0][0]}')
print(f'ë§¨í•´íŠ¼ ìœ ì‚¬ë„ ê°’: {np.round(m_d, 2)[0][0]}')
```

    ìì¹´ë“œ ìœ ì‚¬ë„ ê°’: 0.228
    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’: 0.13
    ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„ ê°’: 0.19
    ë§¨í•´íŠ¼ ìœ ì‚¬ë„ ê°’: 0.88
    

#### => ì¸¡ì • ë°©ë²•ì— ë”°ë¼ í¬ê²Œ ìœ ì‚¬ë„ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ë„í•˜ëŠ” ë°©í–¥ì— ë§ëŠ” ì¸¡ì •ë²• ê³ ë¥´ëŠ” ê²ƒì´ ì¤‘ìš”
